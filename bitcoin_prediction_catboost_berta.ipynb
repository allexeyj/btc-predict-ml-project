{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64548597",
   "metadata": {},
   "source": [
    "# Предсказание курса биткоина с использованием CatBoost и BERTA\n",
    "\n",
    "Этот ноутбук демонстрирует, как предсказывать цены биткоина, комбинируя:\n",
    "1. Анализ текста новостных заголовков с использованием модели BERTA от Hugging Face\n",
    "2. Традиционные признаки, обрабатываемые с помощью CatBoost\n",
    "\n",
    "Мы сгенерируем эмбеддинги из новостных данных и объединим их с другими релевантными признаками для обучения прогностической модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad8af55",
   "metadata": {},
   "source": [
    "## 1. Установка необходимых библиотек\n",
    "\n",
    "Установим необходимые пакеты с помощью `uv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f83fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка необходимых библиотек с помощью uv\n",
    "!uv pip install catboost transformers pandas numpy scikit-learn torch matplotlib seaborn yfinance tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a4af8e",
   "metadata": {},
   "source": [
    "## 2. Импорт библиотек\n",
    "\n",
    "Импортируем все необходимые библиотеки для нашего анализа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca950b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовая обработка данных\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Модели и метрики\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Обработка текста и эмбеддинги\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# Данные биткоина\n",
    "import yfinance as yf\n",
    "\n",
    "# Конфигурация\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3051a8",
   "metadata": {},
   "source": [
    "## 3. Загрузка и предобработка новостных данных\n",
    "\n",
    "Загрузим наши новостные данные и выполним предобработку текста:\n",
    "- Очистка и нормализация\n",
    "- Удаление стоп-слов\n",
    "- Токенизация для входа в модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16edaf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_articles(file_path: str) -> list:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        articles = json.load(f)\n",
    "    return articles\n",
    "\n",
    "\n",
    "# Загрузка статей из обоих источников\n",
    "print(\"Загрузка статей Bitcoin Magazine...\")\n",
    "try:\n",
    "    btc_magazine_articles = load_json_articles(\"BitcoinMagazine_Articles.json\")\n",
    "    print(f\"Загружено {len(btc_magazine_articles)} статей из Bitcoin Magazine\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка загрузки статей Bitcoin Magazine: {e}\")\n",
    "    btc_magazine_articles = []\n",
    "\n",
    "print(\"\\nЗагрузка статей CoinTelegraph...\")\n",
    "try:\n",
    "    cointelegraph_articles = load_json_articles(\"CoinTelegraph_Articles.json\")\n",
    "    print(f\"Загружено {len(cointelegraph_articles)} статей из CoinTelegraph\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка загрузки статей CoinTelegraph: {e}\")\n",
    "    cointelegraph_articles = []\n",
    "\n",
    "\n",
    "def articles_to_dataframe(articles: list, source_name: str) -> pd.DataFrame:\n",
    "    data = []\n",
    "    # Применяем разную логику парсинга в зависимости от источника\n",
    "    if source_name == \"CoinTelegraph\":\n",
    "        for article in tqdm(articles, desc=f\"Обработка {source_name}\"):\n",
    "            if \"title\" in article and \"published_time\" in article:\n",
    "                try:\n",
    "                    date = pd.to_datetime(article[\"published_time\"])\n",
    "                    data.append(\n",
    "                        {\n",
    "                            \"date\": date,\n",
    "                            \"headline\": article.get(\"title\", \"\"),\n",
    "                            \"content\": article.get(\"text\", \"\"),\n",
    "                            \"url\": article.get(\"url\", \"\"),\n",
    "                            \"views\": article.get(\"views\", 0),\n",
    "                            \"source\": source_name,\n",
    "                        }\n",
    "                    )\n",
    "                except:\n",
    "                    pass\n",
    "    elif source_name == \"Bitcoin Magazine\":\n",
    "        for article in tqdm(articles, desc=f\"Обработка {source_name}\"):\n",
    "            if \"title\" in article and \"published_time\" in article:\n",
    "                try:\n",
    "                    date = pd.to_datetime(article[\"published_time\"])\n",
    "                    data.append(\n",
    "                        {\n",
    "                            \"date\": date,\n",
    "                            \"headline\": article.get(\"title\", \"\"),\n",
    "                            \"content\": article.get(\"text\", \"\"),\n",
    "                            \"url\": article.get(\"url\", \"\"),\n",
    "                            \"source\": source_name,\n",
    "                        }\n",
    "                    )\n",
    "                except:\n",
    "                    pass\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Преобразование статей в DataFrame\n",
    "btc_magazine_df = articles_to_dataframe(btc_magazine_articles, \"Bitcoin Magazine\")\n",
    "cointelegraph_df = articles_to_dataframe(cointelegraph_articles, \"CoinTelegraph\")\n",
    "\n",
    "# Объединение всех источников новостей\n",
    "news_data = pd.concat([btc_magazine_df, cointelegraph_df], ignore_index=True)\n",
    "\n",
    "# Сортировка по дате\n",
    "news_data = news_data.sort_values(\"date\")\n",
    "\n",
    "print(f\"\\nВсего новостных статей: {len(news_data)}\")\n",
    "print(\"Диапазон дат:\", news_data[\"date\"].min(), \"до\", news_data[\"date\"].max())\n",
    "print(\"\\nПример данных:\")\n",
    "print(news_data.head())\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "\n",
    "# Применение очистки текста с использованием progress_apply\n",
    "print(\"\\nОчистка текстовых данных...\")\n",
    "news_data[\"clean_headline\"] = news_data[\"headline\"].progress_apply(clean_text)\n",
    "news_data[\"clean_content\"] = news_data[\"content\"].progress_apply(clean_text)\n",
    "\n",
    "# Вывод примера очищенных данных\n",
    "print(\"\\nПримеры очищенных текстов:\")\n",
    "print(news_data[[\"clean_headline\", \"clean_content\"]].head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a43b5ab",
   "metadata": {},
   "source": [
    "## 4. Загрузка предобученной модели BERTA из Hugging Face\n",
    "\n",
    "Будем использовать модель sergeyzh/BERTA из Hugging Face, которая специально настроена для русского текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effac5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка предобученной модели BERTA из Hugging Face\n",
    "model_name = \"sergeyzh/BERTA\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "berta_model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Перенос модели на GPU, если доступно\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "berta_model = berta_model.to(device)\n",
    "print(f\"Используется устройство: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d62220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool(\n",
    "    hidden_state: torch.Tensor, mask: torch.Tensor, pooling_method: str = \"mean\"\n",
    ") -> torch.Tensor:\n",
    "    if pooling_method == \"mean\":\n",
    "        s = torch.sum(hidden_state * mask.unsqueeze(-1).float(), dim=1)\n",
    "        d = mask.sum(axis=1, keepdim=True).float()\n",
    "        return s / d\n",
    "    elif pooling_method == \"cls\":\n",
    "        return hidden_state[:, 0]\n",
    "    elif pooling_method == \"max\":\n",
    "        masked = hidden_state * mask.unsqueeze(-1).float()\n",
    "        masked_fill = masked + (1 - mask.unsqueeze(-1).float()) * -1e9\n",
    "        return torch.max(masked_fill, dim=1)[0]\n",
    "    else:\n",
    "        raise ValueError(f\"Неизвестный метод пулинга: {pooling_method}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62ad015",
   "metadata": {},
   "source": [
    "## 5. Генерация текстовых эмбеддингов\n",
    "\n",
    "Теперь используем модель BERTA для генерации эмбеддингов нашего новостного текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a752de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(\n",
    "    texts: list, max_length: int = 256, pooling_method: str = \"mean\"\n",
    ") -> np.ndarray:\n",
    "    encoded_input = tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output = berta_model(**encoded_input)\n",
    "\n",
    "    sentence_embeddings = pool(\n",
    "        model_output.last_hidden_state,\n",
    "        encoded_input[\"attention_mask\"],\n",
    "        pooling_method=pooling_method,\n",
    "    )\n",
    "\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "    return sentence_embeddings.cpu().numpy()\n",
    "\n",
    "\n",
    "# Генерация эмбеддингов для заголовков и содержания новостей\n",
    "batch_size = 128  # Меньший размер батча для предотвращения проблем с памятью\n",
    "headline_embeddings = []\n",
    "content_embeddings = []\n",
    "\n",
    "print(\"Генерация эмбеддингов заголовков...\")\n",
    "for i in tqdm(range(0, len(news_data), batch_size)):\n",
    "    batch_texts = news_data[\"clean_headline\"][i : i + batch_size].tolist()\n",
    "    batch_embeddings = get_bert_embeddings(batch_texts, pooling_method=\"mean\")\n",
    "    headline_embeddings.extend(batch_embeddings)\n",
    "\n",
    "print(\"\\nГенерация эмбеддингов содержания...\")\n",
    "for i in tqdm(range(0, len(news_data), batch_size)):\n",
    "    batch_texts = news_data[\"clean_content\"][i : i + batch_size].fillna(\"\").tolist()\n",
    "    batch_embeddings = get_bert_embeddings(batch_texts, pooling_method=\"mean\")\n",
    "    content_embeddings.extend(batch_embeddings)\n",
    "\n",
    "# Преобразование эмбеддингов в массивы numpy\n",
    "headline_embeddings = np.array(headline_embeddings)\n",
    "content_embeddings = np.array(content_embeddings)\n",
    "\n",
    "print(f\"Размерность эмбеддингов заголовков: {headline_embeddings.shape}\")\n",
    "print(f\"Размерность эмбеддингов содержания: {content_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edc0ddf",
   "metadata": {},
   "source": [
    "## 6. Подготовка данных для CatBoost\n",
    "\n",
    "Теперь объединим текстовые эмбеддинги с другими релевантными признаками, такими как исторические данные цен, объемы торгов и технические индикаторы, для подготовки нашего набора данных к обучению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5bb972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение самой ранней и самой поздней дат из наших новостных данных\n",
    "start_date = news_data[\"date\"].min().strftime(\"%Y-%m-%d\")\n",
    "end_date = news_data[\"date\"].max().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "start_date_obj = datetime.strptime(start_date, \"%Y-%m-%d\") - timedelta(days=30)\n",
    "end_date_obj = datetime.strptime(end_date, \"%Y-%m-%d\") + timedelta(days=30)\n",
    "start_date = start_date_obj.strftime(\"%Y-%m-%d\")\n",
    "end_date = end_date_obj.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(f\"Загрузка данных о ценах биткоина с {start_date} по {end_date}\")\n",
    "\n",
    "# Загрузка данных о ценах биткоина\n",
    "btc_price = yf.download(\"BTC-USD\", start=start_date, end=end_date)\n",
    "btc_price.reset_index(inplace=True)\n",
    "btc_price.rename(\n",
    "    columns={\n",
    "        \"Date\": \"date\",\n",
    "        \"Close\": \"price\",\n",
    "        \"Volume\": \"volume\",\n",
    "        \"Open\": \"open\",\n",
    "        \"High\": \"high\",\n",
    "        \"Low\": \"low\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "print(f\"Загружено {len(btc_price)} записей исторических цен\")\n",
    "print(btc_price.head())\n",
    "\n",
    "# Убедимся, что даты в формате datetime\n",
    "news_data[\"date\"] = (\n",
    "    pd.to_datetime(news_data[\"date\"], utc=True).dt.tz_localize(None).dt.date\n",
    ")\n",
    "btc_price[\"date\"] = (\n",
    "    pd.to_datetime(btc_price[\"date\"], utc=True).dt.tz_localize(None).dt.date\n",
    ")\n",
    "\n",
    "# Объединяем эмбеддинги заголовков с данными о ценах на основе даты\n",
    "# Сначала создаем DataFrame с датой и эмбеддингами\n",
    "headline_emb_df = pd.DataFrame(\n",
    "    headline_embeddings,\n",
    "    columns=[f\"h_emb_{i}\" for i in range(headline_embeddings.shape[1])],\n",
    ")\n",
    "headline_emb_df[\"date\"] = news_data[\"date\"].values\n",
    "\n",
    "# Создаем DataFrame для эмбеддингов содержания\n",
    "content_emb_df = pd.DataFrame(\n",
    "    content_embeddings,\n",
    "    columns=[f\"c_emb_{i}\" for i in range(content_embeddings.shape[1])],\n",
    ")\n",
    "content_emb_df[\"date\"] = news_data[\"date\"].values\n",
    "\n",
    "# Группируем по дате и усредняем эмбеддинги для одного дня\n",
    "daily_headline_emb = headline_emb_df.groupby(\"date\").mean().reset_index()\n",
    "daily_content_emb = content_emb_df.groupby(\"date\").mean().reset_index()\n",
    "\n",
    "# Объединяем эмбеддинги\n",
    "daily_emb = pd.merge(daily_headline_emb, daily_content_emb, on=\"date\", how=\"inner\")\n",
    "\n",
    "# Объединяем с данными о ценах\n",
    "merged_data = pd.merge(btc_price, daily_emb, on=\"date\", how=\"inner\")\n",
    "print(f\"\\nРазмерность объединенных данных: {merged_data.shape}\")\n",
    "\n",
    "\n",
    "def add_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Добавляет технические индикаторы к DataFrame с ценовыми данными.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame с ценовыми данными\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame с добавленными техническими индикаторами\n",
    "    \"\"\"\n",
    "    # Простые скользящие средние\n",
    "    df[\"SMA7\"] = df[\"price\"].rolling(window=7).mean()\n",
    "    df[\"SMA30\"] = df[\"price\"].rolling(window=30).mean()\n",
    "\n",
    "    # Моментум цены\n",
    "    df[\"price_momentum\"] = df[\"price\"].pct_change(periods=7)\n",
    "\n",
    "    # Волатильность\n",
    "    df[\"volatility\"] = df[\"price\"].rolling(window=7).std()\n",
    "\n",
    "    # Изменение объема торгов\n",
    "    df[\"volume_change\"] = df[\"volume\"].pct_change()\n",
    "\n",
    "    # Диапазон цен\n",
    "    df[\"daily_range\"] = (df[\"high\"] - df[\"low\"]) / df[\"open\"]\n",
    "\n",
    "    # Индекс относительной силы (RSI)\n",
    "    delta = df[\"price\"].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=14).mean()\n",
    "    avg_loss = loss.rolling(window=14).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    df[\"RSI\"] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Добавляем технические индикаторы и обрабатываем пропущенные значения\n",
    "print(\"\\nДобавление технических индикаторов...\")\n",
    "merged_data = add_technical_indicators(merged_data)\n",
    "merged_data = merged_data.dropna()\n",
    "\n",
    "# Подготовка признаков и целевой переменной\n",
    "# Предсказываем изменение цены на следующий день (в процентах)\n",
    "merged_data[\"target_pct_change\"] = merged_data[\"price\"].pct_change(periods=1).shift(-1)\n",
    "merged_data[\"target_direction\"] = (merged_data[\"target_pct_change\"] > 0).astype(\n",
    "    int\n",
    ")  # 1, если цена растет, 0, если падает\n",
    "merged_data[\"target_price\"] = merged_data[\"price\"].shift(\n",
    "    -1\n",
    ")  # Фактическая цена следующего дня\n",
    "merged_data = merged_data.dropna()\n",
    "\n",
    "print(f\"Итоговая размерность данных после предобработки: {merged_data.shape}\")\n",
    "\n",
    "# Определяем признаки\n",
    "price_features = [\n",
    "    \"price\",\n",
    "    \"volume\",\n",
    "    \"SMA7\",\n",
    "    \"SMA30\",\n",
    "    \"price_momentum\",\n",
    "    \"volatility\",\n",
    "    \"volume_change\",\n",
    "    \"daily_range\",\n",
    "    \"RSI\",\n",
    "]\n",
    "\n",
    "\n",
    "# Применяем PCA к эмбеддингам заголовков\n",
    "headline_cols = [col for col in merged_data.columns if col.startswith(\"h_emb_\")]\n",
    "headline_data = merged_data[headline_cols]\n",
    "pca_headline = PCA(n_components=20)\n",
    "headline_pca = pca_headline.fit_transform(headline_data)\n",
    "headline_pca_df = pd.DataFrame(headline_pca, columns=[f\"h_pca_{i}\" for i in range(20)])\n",
    "\n",
    "# Применяем PCA к эмбеддингам содержания\n",
    "content_cols = [col for col in merged_data.columns if col.startswith(\"c_emb_\")]\n",
    "content_data = merged_data[content_cols]\n",
    "pca_content = PCA(n_components=20)\n",
    "content_pca = pca_content.fit_transform(content_data)\n",
    "content_pca_df = pd.DataFrame(content_pca, columns=[f\"c_pca_{i}\" for i in range(20)])\n",
    "\n",
    "# Сбрасываем индекс перед добавлением столбцов PCA\n",
    "merged_data = merged_data.reset_index(drop=True)\n",
    "headline_pca_df = headline_pca_df.reset_index(drop=True)\n",
    "content_pca_df = content_pca_df.reset_index(drop=True)\n",
    "\n",
    "# Добавляем столбцы PCA в merged_data\n",
    "for col in headline_pca_df.columns:\n",
    "    merged_data[col] = headline_pca_df[col].values\n",
    "\n",
    "for col in content_pca_df.columns:\n",
    "    merged_data[col] = content_pca_df[col].values\n",
    "\n",
    "# Определяем все признаки\n",
    "embedding_pca_features = [\n",
    "    col\n",
    "    for col in merged_data.columns\n",
    "    if col.startswith(\"h_pca_\") or col.startswith(\"c_pca_\")\n",
    "]\n",
    "all_features = price_features + embedding_pca_features\n",
    "\n",
    "# Подготовка признаков и целевой переменной\n",
    "X = merged_data[all_features]\n",
    "y_price = merged_data[\"target_price\"]  # Для регрессии (предсказание цены)\n",
    "y_direction = merged_data[\"target_direction\"]  # Для классификации (направление цены)\n",
    "\n",
    "# Разделение данных\n",
    "train_size = int(len(merged_data) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_price_train, y_price_test = y_price[:train_size], y_price[train_size:]\n",
    "y_direction_train, y_direction_test = y_direction[:train_size], y_direction[train_size:]\n",
    "\n",
    "print(f\"\\nОбучающая выборка: {X_train.shape}, Тестовая выборка: {X_test.shape}\")\n",
    "print(\n",
    "    f\"Распределение направления цены в обучающей выборке: {y_direction_train.value_counts()}\"\n",
    ")\n",
    "print(\n",
    "    f\"Распределение направления цены в тестовой выборке: {y_direction_test.value_counts()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ddef40",
   "metadata": {},
   "source": [
    "## 7. Обучение моделей CatBoost\n",
    "\n",
    "Обучим две модели:\n",
    "1. Регрессионную модель для предсказания точной цены биткоина\n",
    "2. Классификационную модель для предсказания направления движения цены (вверх или вниз)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e682a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Обучение CatBoost регрессора для предсказания цены\n",
    "print(\"Обучение модели предсказания цены...\")\n",
    "catboost_regressor = CatBoostRegressor(\n",
    "    iterations=500, learning_rate=0.03, depth=6, loss_function=\"RMSE\", verbose=100\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "catboost_regressor.fit(X_train, y_price_train, eval_set=(X_test, y_price_test))\n",
    "\n",
    "# Делаем предсказания цены\n",
    "y_price_pred = catboost_regressor.predict(X_test)\n",
    "\n",
    "# 2. Обучение CatBoost классификатора для предсказания направления\n",
    "print(\"\\nОбучение модели предсказания направления цены...\")\n",
    "catboost_classifier = CatBoostClassifier(\n",
    "    iterations=500, learning_rate=0.03, depth=6, loss_function=\"Logloss\", verbose=100\n",
    ")\n",
    "\n",
    "# Обучение классификатора\n",
    "catboost_classifier.fit(X_train, y_direction_train, eval_set=(X_test, y_direction_test))\n",
    "\n",
    "# Делаем предсказания направления\n",
    "y_direction_pred = catboost_classifier.predict(X_test)\n",
    "\n",
    "# График важности признаков для модели предсказания цены\n",
    "plt.figure(figsize=(14, 8))\n",
    "feature_importance = catboost_regressor.get_feature_importance()\n",
    "feature_names = X_train.columns\n",
    "importance_df = pd.DataFrame({\"Признак\": feature_names, \"Важность\": feature_importance})\n",
    "importance_df = importance_df.sort_values(\"Важность\", ascending=False).head(20)\n",
    "\n",
    "plt.barh(importance_df[\"Признак\"], importance_df[\"Важность\"])\n",
    "plt.title(\"Важность признаков для предсказания цены (Топ-20)\")\n",
    "plt.xlabel(\"Важность\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# График важности признаков для модели предсказания направления\n",
    "plt.figure(figsize=(14, 8))\n",
    "feature_importance = catboost_classifier.get_feature_importance()\n",
    "feature_names = X_train.columns\n",
    "importance_df = pd.DataFrame({\"Признак\": feature_names, \"Важность\": feature_importance})\n",
    "importance_df = importance_df.sort_values(\"Важность\", ascending=False).head(20)\n",
    "\n",
    "plt.barh(importance_df[\"Признак\"], importance_df[\"Важность\"])\n",
    "plt.title(\"Важность признаков для предсказания направления (Топ-20)\")\n",
    "plt.xlabel(\"Важность\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcbf33b",
   "metadata": {},
   "source": [
    "## 8. Оценка моделей\n",
    "\n",
    "Теперь оценим обе модели предсказания, используя соответствующие метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7bf8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка регрессионной модели (предсказание цены)\n",
    "print(\"Оценка модели предсказания цены...\")\n",
    "rmse = np.sqrt(mean_squared_error(y_price_test, y_price_pred))\n",
    "mae = mean_absolute_error(y_price_test, y_price_pred)\n",
    "r2 = r2_score(y_price_test, y_price_pred)\n",
    "\n",
    "print(f\"Корень среднеквадратичной ошибки (RMSE): ${rmse:.2f}\")\n",
    "print(f\"Средняя абсолютная ошибка (MAE): ${mae:.2f}\")\n",
    "print(f\"Коэффициент детерминации (R²): {r2:.4f}\")\n",
    "\n",
    "# Расчет процентной ошибки\n",
    "y_test_array = np.array(y_price_test)\n",
    "percentage_error = np.abs((y_test_array - y_price_pred) / y_test_array) * 100\n",
    "mean_percentage_error = np.mean(percentage_error)\n",
    "print(f\"Средняя процентная ошибка: {mean_percentage_error:.2f}%\")\n",
    "\n",
    "# Оценка классификационной модели (предсказание направления)\n",
    "print(\"\\nОценка модели предсказания направления цены...\")\n",
    "accuracy = accuracy_score(y_direction_test, y_direction_pred)\n",
    "print(f\"Точность: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nОтчет по классификации:\")\n",
    "print(classification_report(y_direction_test, y_direction_pred))\n",
    "\n",
    "print(\"\\nМатрица ошибок:\")\n",
    "conf_mat = confusion_matrix(y_direction_test, y_direction_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "# График реальных и предсказанных цен\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(y_price_test.values, label=\"Реальная цена\", color=\"blue\")\n",
    "plt.plot(y_price_pred, label=\"Предсказанная цена\", color=\"red\", linestyle=\"--\")\n",
    "plt.title(\"Предсказание цены биткоина: Реальная vs Предсказанная\")\n",
    "plt.xlabel(\"Время\")\n",
    "plt.ylabel(\"Цена (USD)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# График распределения ошибок предсказания\n",
    "plt.figure(figsize=(12, 6))\n",
    "error = y_price_test.values - y_price_pred\n",
    "sns.histplot(error, kde=True)\n",
    "plt.title(\"Распределение ошибок предсказания\")\n",
    "plt.xlabel(\"Ошибка предсказания (USD)\")\n",
    "plt.ylabel(\"Частота\")\n",
    "plt.axvline(x=0, color=\"red\", linestyle=\"--\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Визуализация матрицы ошибок\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    conf_mat,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Вниз\", \"Вверх\"],\n",
    "    yticklabels=[\"Вниз\", \"Вверх\"],\n",
    ")\n",
    "plt.title(\"Матрица ошибок\")\n",
    "plt.xlabel(\"Предсказано\")\n",
    "plt.ylabel(\"Фактически\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546a2eda",
   "metadata": {},
   "source": [
    "## 9. Предсказания на новых данных\n",
    "\n",
    "Создадим функцию для предсказания на новых, неизвестных новостных статьях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75632982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_new_article(\n",
    "    headline: str, content: str, current_price: float, current_volume: float\n",
    ") -> dict:\n",
    "    \"\"\"Делает предсказание на основе новой статьи и текущих рыночных данных.\n",
    "\n",
    "    Args:\n",
    "        headline: Заголовок новости\n",
    "        content: Содержание новости\n",
    "        current_price: Текущая цена биткоина\n",
    "        current_volume: Текущий объем торгов биткоина\n",
    "\n",
    "    Returns:\n",
    "        dict: Словарь с результатами предсказания\n",
    "    \"\"\"\n",
    "    # Очистка текста\n",
    "    clean_headline = clean_text(headline)\n",
    "    clean_content = clean_text(content)\n",
    "\n",
    "    # Генерация эмбеддингов\n",
    "    headline_embedding = get_bert_embeddings([clean_headline])[0]\n",
    "    content_embedding = get_bert_embeddings([clean_content])[0]\n",
    "\n",
    "    # Преобразование с помощью PCA\n",
    "    h_pca = pca_headline.transform([headline_embedding])[0]\n",
    "    c_pca = pca_content.transform([content_embedding])[0]\n",
    "\n",
    "    # Создание строки признаков\n",
    "    features = {feature: 0 for feature in all_features}\n",
    "\n",
    "    # Заполняем ценовые признаки разумными значениями\n",
    "    features[\"price\"] = current_price\n",
    "    features[\"volume\"] = current_volume\n",
    "    features[\"SMA7\"] = current_price  # упрощенно\n",
    "    features[\"SMA30\"] = current_price  # упрощенно\n",
    "    features[\"price_momentum\"] = 0.0  # заполнитель\n",
    "    features[\"volatility\"] = 0.0  # заполнитель\n",
    "    features[\"volume_change\"] = 0.0  # заполнитель\n",
    "    features[\"daily_range\"] = 0.01  # заполнитель\n",
    "    features[\"RSI\"] = 50  # заполнитель (нейтральный RSI)\n",
    "\n",
    "    # Добавляем признаки PCA\n",
    "    for i, val in enumerate(h_pca):\n",
    "        features[f\"h_pca_{i}\"] = val\n",
    "\n",
    "    for i, val in enumerate(c_pca):\n",
    "        features[f\"c_pca_{i}\"] = val\n",
    "\n",
    "    # Преобразуем в DataFrame\n",
    "    features_df = pd.DataFrame([features])\n",
    "\n",
    "    # Делаем предсказания\n",
    "    price_prediction = catboost_regressor.predict(features_df)[0]\n",
    "    direction_proba = catboost_classifier.predict_proba(features_df)[0]\n",
    "    direction = \"Вверх ↑\" if direction_proba[1] > 0.5 else \"Вниз ↓\"\n",
    "    confidence = (\n",
    "        direction_proba[1] if direction == \"Вверх ↑\" else 1 - direction_proba[1]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"predicted_price\": price_prediction,\n",
    "        \"price_change\": price_prediction - current_price,\n",
    "        \"price_change_pct\": (price_prediction - current_price) / current_price * 100,\n",
    "        \"predicted_direction\": direction,\n",
    "        \"confidence\": confidence * 100,\n",
    "    }\n",
    "\n",
    "\n",
    "# Тестирование функции предсказания на примере статьи\n",
    "sample_headline = \"Bitcoin Surges as Institutional Investors Increase Holdings\"\n",
    "sample_content = \"\"\"\n",
    "Major financial institutions are significantly increasing their Bitcoin positions amid growing optimism about\n",
    "regulatory clarity in the cryptocurrency sector. According to recent filings, several Wall Street firms have\n",
    "doubled their BTC holdings in the last quarter, signaling strong institutional confidence in the leading cryptocurrency.\n",
    "\"\"\"\n",
    "\n",
    "# Получаем текущую цену биткоина из Yahoo Finance\n",
    "current_btc = yf.Ticker(\"BTC-USD\")\n",
    "current_price = current_btc.history(period=\"1d\")[\"Close\"].iloc[0]\n",
    "current_volume = current_btc.history(period=\"1d\")[\"Volume\"].iloc[0]\n",
    "\n",
    "prediction = predict_with_new_article(\n",
    "    sample_headline, sample_content, current_price, current_volume\n",
    ")\n",
    "\n",
    "print(f\"Текущая цена BTC: ${current_price:.2f}\")\n",
    "print(f\"Предсказанная цена BTC: ${prediction['predicted_price']:.2f}\")\n",
    "print(\n",
    "    f\"Предсказанное изменение: ${prediction['price_change']:.2f} ({prediction['price_change_pct']:.2f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"Направление: {prediction['predicted_direction']} (Уверенность: {prediction['confidence']:.1f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eef1a59",
   "metadata": {},
   "source": [
    "## Заключение\n",
    "\n",
    "В этом ноутбуке мы создали модель предсказания курса биткоина, используя:\n",
    "\n",
    "1. Текстовые эмбеддинги из новостных статей с помощью модели BERTA от sergeyzh\n",
    "2. Исторические данные о цене и объеме торгов биткоина\n",
    "3. Технические индикаторы рынка\n",
    "\n",
    "Мы обучили две модели CatBoost:\n",
    "- Регрессионную модель для предсказания точной цены биткоина\n",
    "- Классификационную модель для предсказания направления движения цены (вверх или вниз)\n",
    "\n",
    "Результаты показывают, что комбинирование новостного сентимента с техническими индикаторами позволяет достичь лучших результатов, чем использование только одного типа данных./"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
